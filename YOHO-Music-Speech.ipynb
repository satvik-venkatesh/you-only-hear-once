{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOHO-Music-Speech.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satvik-venkatesh/you-only-hear-once/blob/main/YOHO-Music-Speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iQeu-LxPaeV"
      },
      "source": [
        "!pip install sed_eval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg4gdVF1ShXJ"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAr0CO_wC543"
      },
      "source": [
        "import numpy as np\n",
        "#import vaex\n",
        "import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "import IPython\n",
        "import math\n",
        "import glob\n",
        "import sed_eval\n",
        "import dcase_util\n",
        "import pickle\n",
        "import os\n",
        "import soundfile as sf\n",
        "import librosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwC9pZiiAECz"
      },
      "source": [
        "os.mkdir(\"/content/train-zipped\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbh2ezvDDznr"
      },
      "source": [
        "## The below code downloads data. Each wget command downloads data more than 1GB, so ensure the data downloads correctly. If the downloaded file is very small, please run the code block again "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyRiz4xX-sE1"
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-6AN2V6E56MID71gjjCMHtDAGkNr97rp' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-6AN2V6E56MID71gjjCMHtDAGkNr97rp\" -O train-zipped/d1.zip && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDy09PfZ_TNv"
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-9Z3j41byWsh5boziU5feKs0SksCMBav' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-9Z3j41byWsh5boziU5feKs0SksCMBav\" -O train-zipped/d2.zip && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgN9QcON_WO9"
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-Cn1Gnwls8KoZb19-7eFWO8MvKM-u7T2' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-Cn1Gnwls8KoZb19-7eFWO8MvKM-u7T2\" -O train-zipped/d3.zip && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj1sIvT4_W4C"
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-E51YUmfOu9828Cgy2bMYZm8dSHuHnqr' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-E51YUmfOu9828Cgy2bMYZm8dSHuHnqr\" -O train-zipped/d4.zip && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpjtJhW3kRPA"
      },
      "source": [
        "\"\"\"\n",
        "Extract the .zip files into the 'train data' folder.\n",
        "\"\"\"\n",
        "from zipfile import ZipFile\n",
        "\n",
        "for i in range(0, 4):\n",
        "  zip_name = \"/content/train-zipped/d\" + str(i + 1) + \".zip\"\n",
        "  with ZipFile(zip_name, 'r') as zip:\n",
        "    zip.extractall('train data')\n",
        "    print(\"Extracted all sound files into the folder {}\".format(i + 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HezF8sf0A150"
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-xOXLHq55-J4f700oKbEDHFuLxiavit2' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-xOXLHq55-J4f700oKbEDHFuLxiavit2\" -O train-zipped/BBC-Train.zip && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJhBUZPLtLwc"
      },
      "source": [
        "\"\"\"\n",
        "Extracting Train data\n",
        "\"\"\"\n",
        "from zipfile import ZipFile\n",
        "zip_name = \"/content/train-zipped/BBC-Train.zip\"\n",
        "with ZipFile(zip_name, 'r') as zip:\n",
        "  zip.extractall('train data')\n",
        "  print(\"Extracted all sound files into the folder\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmDxouebB6Ts"
      },
      "source": [
        "os.mkdir(\"/content/val-zipped\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWAKeF4GAmTL"
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-y8XbsH5ou5vYSptB7QnhWByj0rkvSol' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-y8XbsH5ou5vYSptB7QnhWByj0rkvSol\" -O val-zipped/BBC-Val.zip && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abrUulu1tK56"
      },
      "source": [
        "\"\"\"\n",
        "Extract the .zip files into the 'val data' folder.\n",
        "\"\"\"\n",
        "from zipfile import ZipFile\n",
        "\n",
        "zip_name = \"/content/val-zipped/BBC-Val.zip\"\n",
        "with ZipFile(zip_name, 'r') as zip:\n",
        "  zip.extractall('validation data')\n",
        "  print(\"Extracted all sound files into the folder {}\".format(i + 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGFSNVqLw8uK"
      },
      "source": [
        "def smoothe_events(events):\n",
        "  music_events = []\n",
        "  speech_events = []\n",
        "  for e in events:\n",
        "    if e[2] == \"speech\":\n",
        "      speech_events.append(e)\n",
        "    elif e[2] == \"music\":\n",
        "      music_events.append(e)\n",
        "\n",
        "  speech_events.sort(key=lambda x: x[0])\n",
        "  music_events.sort(key=lambda x: x[0])\n",
        "\n",
        "\n",
        "  start_speech = -1000\n",
        "  stop_speech = -1000\n",
        "\n",
        "  speech_events_2 = []\n",
        "\n",
        "  max_speech_silence = 0.4\n",
        "  max_music_silence = 0.6\n",
        "  min_dur_speech = 1.3\n",
        "  min_dur_music = 3.4\n",
        "\n",
        "  # max_speech_silence = 0.0\n",
        "  # max_music_silence = 0.0\n",
        "  # min_dur_speech = 0.0\n",
        "  # min_dur_music = 0.0\n",
        "  count = 0\n",
        "\n",
        "  while count < len(speech_events) - 1:\n",
        "    if (speech_events[count][1] >= speech_events[count + 1][0]) or (speech_events[count + 1][0] - speech_events[count][1] <= max_speech_silence):\n",
        "      speech_events[count][1] = max(speech_events[count + 1][1], speech_events[count][1])\n",
        "      del speech_events[count + 1]\n",
        "    else:\n",
        "      count += 1\n",
        "\n",
        "  count = 0\n",
        "\n",
        "  while count < len(music_events) - 1:\n",
        "    if (music_events[count][1] >= music_events[count + 1][0]) or (music_events[count + 1][0] - music_events[count][1] <= max_music_silence):\n",
        "      music_events[count][1] = max(music_events[count + 1][1], music_events[count][1])\n",
        "      del music_events[count + 1]\n",
        "    else:\n",
        "      count += 1\n",
        "\n",
        "\n",
        "  smooth_events = music_events + speech_events\n",
        "\n",
        "\n",
        "  # count = 0\n",
        "  # while count < len(smooth_events):\n",
        "  #   if smooth_events[count][1] - smooth_events[count][0] < min_dur_speech and smooth_events[count][2] == \"speech\":\n",
        "  #     del smooth_events[count]\n",
        "\n",
        "  #   elif smooth_events[count][1] - smooth_events[count][0] < min_dur_music and smooth_events[count][2] == \"music\":\n",
        "  #     del smooth_events[count]\n",
        "\n",
        "  #   else:\n",
        "  #     count += 1\n",
        "\n",
        "  for i in range(len(smooth_events)):\n",
        "    smooth_events[i][0] = round(smooth_events[i][0], 3)\n",
        "    smooth_events[i][1] = round(smooth_events[i][1], 3)\n",
        "\n",
        "  smooth_events.sort(key=lambda x: x[0])\n",
        "\n",
        "  return smooth_events"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pn1_D9XrdCB"
      },
      "source": [
        "def get_universal_labels(events, no_of_div = 26):\n",
        "  \"\"\"Generate the label matrix of an audio sample based on its annotations.\"\"\"\n",
        "  events = smoothe_events(events)\n",
        "  win_length = 8.0/no_of_div\n",
        "  labels = np.zeros((no_of_div, 6))\n",
        "\n",
        "  for e in events:\n",
        "\n",
        "    start_time = float(e[0])\n",
        "    stop_time = float(e[1])\n",
        "\n",
        "    start_bin = int(start_time // win_length)\n",
        "    stop_bin = int(stop_time // win_length)\n",
        "\n",
        "    start_time_2 = start_time - start_bin * win_length\n",
        "    stop_time_2 = stop_time - stop_bin * win_length\n",
        "\n",
        "    n_bins = stop_bin - start_bin\n",
        "\n",
        "    if n_bins == 0:\n",
        "      if e[2] == \"speech\":\n",
        "        labels[start_bin, 0:3] = [1, start_time_2, stop_time_2]\n",
        "\n",
        "      elif e[2] == \"music\":\n",
        "        labels[start_bin, 3:6] = [1, start_time_2, stop_time_2]\n",
        "\n",
        "    elif n_bins == 1:\n",
        "      if e[2] == \"speech\":\n",
        "        labels[start_bin, 0:3] = [1, start_time_2, win_length]\n",
        "\n",
        "      elif e[2] == \"music\":\n",
        "        labels[start_bin, 3:6] = [1, start_time_2, win_length]\n",
        "\n",
        "      if stop_time_2 > 0.0:\n",
        "        if e[2] == \"speech\":\n",
        "          labels[stop_bin, 0:3] = [1, 0.0, stop_time_2]\n",
        "\n",
        "        elif e[2] == \"music\":\n",
        "          labels[stop_bin, 3:6] = [1, 0.0, stop_time_2]\n",
        "\n",
        "    elif n_bins > 1:\n",
        "      if e[2] == \"speech\":\n",
        "        labels[start_bin, 0:3] = [1, start_time_2, win_length]\n",
        "\n",
        "      if e[2] == \"music\":\n",
        "        labels[start_bin, 3:6] = [1, start_time_2, win_length]\n",
        "\n",
        "      for i in range(1, n_bins):\n",
        "        if e[2] == \"speech\":\n",
        "          labels[start_bin + i, 0:3] = [1, 0.0, win_length]\n",
        "\n",
        "        if e[2] == \"music\":\n",
        "          labels[start_bin + i, 3:6] = [1, 0.0, win_length]\n",
        "\n",
        "      if stop_time_2 > 0.0:\n",
        "        if e[2] == \"speech\":\n",
        "          labels[stop_bin, 0:3] = [1, 0.0, stop_time_2]\n",
        "\n",
        "        elif e[2] == \"music\":\n",
        "          labels[stop_bin, 3:6] = [1, 0.0, stop_time_2]\n",
        "\n",
        "  labels[:, [1, 2, 4, 5]] /= win_length\n",
        "\n",
        "  return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl_xq6_Oa_p9"
      },
      "source": [
        "def get_only_binary_labels(events, win_length = 8.0/13):\n",
        "  \"\"\"Generate the label matrix of an audio sample based on its annotations.\"\"\"\n",
        "  events = smoothe_events(events)\n",
        "  labels = np.zeros((2,))\n",
        "\n",
        "  class_list = [e[2] for e in events]\n",
        "\n",
        "  if \"speech\" in class_list:\n",
        "    labels[0] = 1\n",
        "\n",
        "  if \"music\" in class_list:\n",
        "    labels[1] = 1\n",
        "\n",
        "  return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdzTYyFDIeBS"
      },
      "source": [
        "def construct_labels(labels, no_of_steps = 4):\n",
        "  # labels = smoothe_events(labels)\n",
        "\n",
        "  new_labels = np.zeros((no_of_steps, 6))\n",
        "  win_width = 8.0 / no_of_steps\n",
        "\n",
        "\n",
        "  for i in range(len(labels)):\n",
        "    s = labels[i][0] / win_width\n",
        "    s = min(np.floor(s), no_of_steps - 1)\n",
        "\n",
        "    r = s * win_width\n",
        "\n",
        "    if labels[i][2] == \"speech\":\n",
        "      new_labels[int(s)][0] = 1\n",
        "\n",
        "      t1 = (labels[i][0] - r) / win_width\n",
        "      t2 = (labels[i][1] - labels[i][0]) / win_width\n",
        "\n",
        "      new_labels[int(s)][1] = t1\n",
        "      new_labels[int(s)][2] = t2\n",
        "\n",
        "    elif labels[i][2] == \"music\":\n",
        "      new_labels[int(s)][3] = 1\n",
        "\n",
        "      t1 = (labels[i][0] - r) / win_width\n",
        "      t2 = (labels[i][1] - labels[i][0]) / win_width\n",
        "\n",
        "      new_labels[int(s)][4] = t1\n",
        "      new_labels[int(s)][5] = t2\n",
        "\n",
        "  return new_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Di90pJW1wl9"
      },
      "source": [
        "def to_seg_by_class(events, n_frames = 801):\n",
        "  events = smoothe_events(events)\n",
        "  labels = np.zeros((n_frames, 2), dtype=np.float32)\n",
        "\n",
        "  for e in events:\n",
        "    t1 = float(e[0])\n",
        "    t1 = int(t1 / 160 * 16000)\n",
        "    t2 = float(e[1])\n",
        "    t2 = int(t2 / 160 * 16000)\n",
        "\n",
        "    if e[2] == 'speech':\n",
        "      labels[t1:t2, 0] = 1\n",
        "    elif e[2] == 'music':\n",
        "      labels[t1:t2, 1] = 1\n",
        "  \n",
        "  return labels "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CExw_CqmfYik"
      },
      "source": [
        "events = [[0.2, 4.3, \"music\"], [3.6, 6.0, \"speech\"]]\n",
        "ss = get_universal_labels(events)\n",
        "print(ss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJhcdQV4FvNV"
      },
      "source": [
        "def get_log_melspectrogram(audio, sr = 16000, hop_length = 160, win_length = 400, n_fft = 512, n_mels = 64, fmin = 125, fmax = 7500):\n",
        "    \"\"\"Return the log-scaled Mel bands of an audio signal.\"\"\"\n",
        "    bands = librosa.feature.melspectrogram(\n",
        "        y=audio, sr=sr, hop_length=hop_length, win_length = win_length, n_fft=n_fft, n_mels=n_mels, fmin=fmin, fmax=fmax, dtype=np.float32)\n",
        "    return librosa.core.power_to_db(bands, amin=1e-7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HqrFP6VxEEJ"
      },
      "source": [
        "labels = glob.glob(\"/content/train data/content/**/mel-id-label-[0-9]*.pickle\", recursive=True)\n",
        "\n",
        "for ll in labels:\n",
        "  with open(ll, 'rb') as f:\n",
        "    n = pickle.load(f)\n",
        "  n2 = get_universal_labels(n)\n",
        "  np.save(ll.replace(\".pickle\", \".npy\"), n2)\n",
        "\n",
        "\n",
        "labels = glob.glob(\"/content/validation data/**/mel-id-label-[0-9]*.pickle\", recursive=True)\n",
        "\n",
        "for ll in labels:\n",
        "  with open(ll, 'rb') as f:\n",
        "    n = pickle.load(f)\n",
        "  n2 = get_universal_labels(n)\n",
        "  np.save(ll.replace(\".pickle\", \".npy\"), n2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ8m-5Kl7JAb"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_examples, batch_size=128, epoch_size = 16384, dim=(1, ),\n",
        "                 n_classes=2, shuffle=True):\n",
        "        'Initialization'\n",
        "        print(\"Constructor called!!!\")\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.epoch_size = epoch_size\n",
        "        self.list_examples = list_examples\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        #print(\"The self.list_examples is {}\".format(self.list_examples))\n",
        "        return int(np.floor(len(self.list_examples) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_examples[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "      self.indexes = np.arange(len(self.list_examples))\n",
        "      if self.shuffle == True:\n",
        "          np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        # 'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # # Initialization\n",
        "        X = np.empty([self.batch_size, 801, 64, 1], dtype=np.float64)\n",
        "        y = np.empty([self.batch_size, 26, 6], dtype=np.float64)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "          # Store sample\n",
        "\n",
        "          xx = np.load(ID[0])\n",
        "          X[i, :, :, 0] = xx\n",
        "\n",
        "          # Store class\n",
        "          yy = np.load(ID[1])\n",
        "          # yy2 = yy[:, [1, 2, 4, 5]]\n",
        "          y[i, :, :] = yy\n",
        "\n",
        "        # v = X.shape[0]\n",
        "        # tau = X.shape[1]\n",
        "\n",
        "        # warped_frequency_spectrogram = spec_augment_tensorflow.frequency_masking(X, v=v)\n",
        "        # warped_frequency_time_sepctrogram = spec_augment_tensorflow.time_masking(warped_frequency_spectrogram, tau=tau)\n",
        "\n",
        "        # X = warped_frequency_time_sepctrogram\n",
        "\n",
        "        return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kh1_gI_vKMO"
      },
      "source": [
        "import re\n",
        "\n",
        "def tryint(s):\n",
        "    try:\n",
        "        return int(s)\n",
        "    except ValueError:\n",
        "        return s\n",
        "    \n",
        "def alphanum_key(s):\n",
        "    \"\"\" Turn a string into a list of string and number chunks.\n",
        "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
        "    \"\"\"\n",
        "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
        "\n",
        "def sort_nicely(l):\n",
        "    \"\"\" Sort the given list in the way that humans expect.\n",
        "    \"\"\"\n",
        "    l.sort(key=alphanum_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx3diPkTbs-W"
      },
      "source": [
        "import glob\n",
        "import random\n",
        "\"\"\"\n",
        "Load the individual numpy arrays into partition\n",
        "\"\"\"\n",
        "data = glob.glob(\"/content/train data/content/**/mel-id-[0-9]*.npy\", recursive=True) \n",
        "sort_nicely(data)\n",
        "\n",
        "labels = glob.glob(\"/content/train data/content/**/mel-id-label-[0-9]*.npy\", recursive=True)\n",
        "sort_nicely(labels)\n",
        "\n",
        "train_examples = [(data[i], labels[i]) for i in range(len(data))]\n",
        "\n",
        "random.seed(4)\n",
        "random.shuffle(train_examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVSvjL_2CSsj"
      },
      "source": [
        "len(train_examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phPv7YAbej_-"
      },
      "source": [
        "\"\"\"\n",
        "Creating the train partition.\n",
        "\"\"\"\n",
        "m_train = 25184\n",
        "random.seed()\n",
        "random.shuffle(train_examples)\n",
        "\n",
        "data_MS = glob.glob(\"/content/train data/MuSpeak/content/Mel Files/**/mel-id-[0-9]*.npy\", recursive=True) \n",
        "sort_nicely(data_MS)\n",
        "\n",
        "labels_MS = glob.glob(\"/content/train data/MuSpeak/content/Mel Files/**/mel-id-label-[0-9]*.npy\", recursive=True)\n",
        "sort_nicely(labels_MS)\n",
        "\n",
        "train_examples_MS = [(data_MS[i], labels_MS[i]) for i in range(len(data_MS))]\n",
        "\n",
        "partition = {}\n",
        "partition['train'] = train_examples[0:m_train] + train_examples_MS\n",
        "\n",
        "random.shuffle(partition['train'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXPkenT6d9iL"
      },
      "source": [
        "print(\"The size of partition['train'] is {}\".format(len(partition['train'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sianBGv5hkr0"
      },
      "source": [
        "\"\"\"\n",
        "This loads data for the validation set.\n",
        "\"\"\"\n",
        "import glob\n",
        "import random\n",
        "\n",
        "data = glob.glob(\"/content/validation data/**/mel-id-[0-9]*.npy\", recursive=True)\n",
        "sort_nicely(data)\n",
        "\n",
        "labels = glob.glob(\"/content/validation data/**/mel-id-label-[0-9]*.npy\", recursive=True)\n",
        "sort_nicely(labels)\n",
        "\n",
        "validation_examples = [(data[i], labels[i]) for i in range(len(data))]\n",
        "\n",
        "random.seed(4)\n",
        "random.shuffle(validation_examples)\n",
        "print(validation_examples[0])\n",
        "\n",
        "# m = len(test_examples)\n",
        "# m_validation = 1024\n",
        "# m_test = 512\n",
        "# m_train = m - m_validation - m_test\n",
        "\n",
        "partition['validation'] = validation_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSBGoa9wCdJj"
      },
      "source": [
        "len(partition['train'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZzW248zAFTC"
      },
      "source": [
        "# Parametersa\n",
        "params = {'dim': (1, ),\n",
        "          'batch_size': 32,\n",
        "          'epoch_size': 0,\n",
        "          'n_classes': 2,\n",
        "          'shuffle': True}\n",
        "\n",
        "# Generators\n",
        "training_generator = DataGenerator(partition['train'], **params)\n",
        "validation_generator = DataGenerator(partition['validation'], **params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK4DX4KA5sDy"
      },
      "source": [
        "\"\"\"\n",
        "This function was adapted from Lemaire et al. 2019. \n",
        "\"\"\"\n",
        "\n",
        "def smooth_output(output, min_speech=1.3, min_music=3.4, max_silence_speech=0.4, max_silence_music=0.6):\n",
        "    duration_frame = 220 / 22050\n",
        "    n_frame = output.shape[1]\n",
        "\n",
        "    start_music = -1000\n",
        "    start_speech = -1000\n",
        "\n",
        "    for i in range(n_frame):\n",
        "        if output[0, i] == 1:\n",
        "            if i - start_speech > 1:\n",
        "                if (i - start_speech) * duration_frame <= max_silence_speech:\n",
        "                    output[0, start_speech:i] = 1\n",
        "\n",
        "            start_speech = i\n",
        "\n",
        "        if output[1, i] == 1:\n",
        "            if i - start_music > 1:\n",
        "                if (i - start_music) * duration_frame <= max_silence_music:\n",
        "                    output[1, start_music:i] = 1\n",
        "\n",
        "            start_music = i\n",
        "\n",
        "    start_music = -1000\n",
        "    start_speech = -1000\n",
        "\n",
        "    for i in range(n_frame):\n",
        "        if i != n_frame - 1:\n",
        "            if output[0, i] == 0:\n",
        "                if i - start_speech > 1:\n",
        "                    if (i - start_speech) * duration_frame <= min_speech:\n",
        "                        output[0, start_speech:i] = 0\n",
        "\n",
        "                start_speech = i\n",
        "\n",
        "            if output[1, i] == 0:\n",
        "                if i - start_music > 1:\n",
        "                    if (i - start_music) * duration_frame <= min_music:\n",
        "                        output[1, start_music:i] = 0\n",
        "\n",
        "                start_music = i\n",
        "        else:\n",
        "            if i - start_speech > 1:\n",
        "                if (i - start_speech) * duration_frame <= min_speech:\n",
        "                    output[0, start_speech:i + 1] = 0\n",
        "\n",
        "            if i - start_music > 1:\n",
        "                if (i - start_music) * duration_frame <= min_music:\n",
        "                    output[1, start_music:i + 1] = 0\n",
        "\n",
        "    return output\n",
        "\n",
        "\"\"\"\n",
        "This function converts the predictions made by the neural network into a format that is understood by sed_eval.\n",
        "\"\"\"\n",
        "\n",
        "def preds_to_se(p, audio_clip_length = 8.0):\n",
        "  start_speech = -100\n",
        "  start_music = -100\n",
        "  stop_speech = -100\n",
        "  stop_music = -100\n",
        "\n",
        "  audio_events = []\n",
        "\n",
        "  n_frames = p.shape[0]\n",
        "\n",
        "  if p[0, 0] == 1:\n",
        "    start_speech = 0\n",
        "  \n",
        "  if p[0, 1] == 1:\n",
        "    start_music = 0\n",
        "\n",
        "  for i in range(n_frames - 1):\n",
        "    if p[i, 0] == 0 and p[i + 1, 0] == 1:\n",
        "      start_speech = i + 1\n",
        "\n",
        "    elif p[i, 0] == 1 and p[i + 1, 0] == 0:\n",
        "      stop_speech = i\n",
        "      start_time = frames_to_time(start_speech)\n",
        "      stop_time = frames_to_time(stop_speech)\n",
        "      audio_events.append((start_time, stop_time, \"speech\"))\n",
        "      start_speech = -100\n",
        "      stop_speech = -100\n",
        "\n",
        "    if p[i, 1] == 0 and p[i + 1, 1] == 1:\n",
        "      start_music = i + 1\n",
        "    elif p[i, 1] == 1 and p[i + 1, 1] == 0:\n",
        "      stop_music = i\n",
        "      start_time = frames_to_time(start_music)\n",
        "      stop_time = frames_to_time(stop_music)      \n",
        "      audio_events.append((start_time, stop_time, \"music\"))\n",
        "      start_music = -100\n",
        "      stop_music = -100\n",
        "\n",
        "  if start_speech != -100:\n",
        "    start_time = frames_to_time(start_speech)\n",
        "    stop_time = audio_clip_length\n",
        "    audio_events.append((start_time, stop_time, \"speech\"))\n",
        "    start_speech = -100\n",
        "    stop_speech = -100\n",
        "\n",
        "  if start_music != -100:\n",
        "    start_time = frames_to_time(start_music)\n",
        "    stop_time = audio_clip_length\n",
        "    audio_events.append((start_time, stop_time, \"music\"))\n",
        "    start_music = -100\n",
        "    stop_music = -100\n",
        "\n",
        "  audio_events.sort(key = lambda x: x[0]) \n",
        "  return audio_events\n",
        "\n",
        "def frames_to_time(f, sr = 22050.0, hop_size = 220):\n",
        "  return f * hop_size / sr\n",
        "\n",
        "def get_log_melspectrogram(audio, sr = 16000, hop_length = 160, win_length = 400, n_fft = 512, n_mels = 64, fmin = 125, fmax = 7500):\n",
        "    \"\"\"Return the log-scaled Mel bands of an audio signal.\"\"\"\n",
        "    bands = librosa.feature.melspectrogram(\n",
        "        y=audio, sr=sr, hop_length=hop_length, win_length = win_length, n_fft=n_fft, n_mels=n_mels, fmin=fmin, fmax=fmax, dtype=np.float32)\n",
        "    return librosa.core.power_to_db(bands, amin=1e-7)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Make predictions for full audio.\n",
        "\"\"\"\n",
        "def mk_preds_fa(audio_path, hop_size = 6.0, discard = 1.0, win_length = 8.0, sampling_rate = 22050):\n",
        "  in_signal, in_sr = sf.read(audio_path)\n",
        "\n",
        "  # Resample the audio file.\n",
        "  in_signal_22k = librosa.resample(in_signal, orig_sr=in_sr, target_sr=sampling_rate)\n",
        "  in_signal = np.copy(in_signal_22k)\n",
        "\n",
        "  audio_clip_length_samples = in_signal.shape[0]\n",
        "  print('audio_clip_length_samples is {}'.format(audio_clip_length_samples))\n",
        "\n",
        "  #hop_size_samples = int(hop_size * sampling_rate)\n",
        "  hop_size_samples = 220 * 602 - 1\n",
        "\n",
        "  #win_length_samples = int(win_length * sampling_rate)\n",
        "  win_length_samples = 220 * 802 - 1\n",
        "\n",
        "  n_preds = int(math.ceil((audio_clip_length_samples - win_length_samples) / hop_size_samples)) + 1\n",
        "\n",
        "  #print('n_preds is {}'.format(n_preds))\n",
        "\n",
        "  in_signal_pad = np.zeros((n_preds * hop_size_samples + 200 * 220))\n",
        "\n",
        "  #print('in_signal_pad.shape is {}'.format(in_signal_pad.shape))\n",
        "\n",
        "  in_signal_pad[0:audio_clip_length_samples] = in_signal\n",
        "\n",
        "  preds = np.zeros((n_preds, 802, 2))\n",
        "  mss_in = np.zeros((n_preds, 802, 80))\n",
        "\n",
        "  for i in range(n_preds):\n",
        "    seg = in_signal_pad[i * hop_size_samples:(i * hop_size_samples) + win_length_samples]\n",
        "    #print('seg.shape is {}'.format(seg.shape))\n",
        "    seg = librosa.util.normalize(seg)\n",
        "\n",
        "    mss = get_log_melspectrogram(seg)\n",
        "    M = mss.T\n",
        "    mss_in[i, :, :] = M\n",
        "\n",
        "  preds = (model.predict(mss_in) >= (0.5, 0.5)).astype(np.float)\n",
        "  #p = cat_to_multi(p)\n",
        "\n",
        "  # preds[i, :, :] = p[0]\n",
        "\n",
        "  #discard_frames = 100\n",
        "  #oa_preds = np.zeros((, 128)) # overall predictions\n",
        "\n",
        "  preds_mid = np.copy(preds[1:-1, 100:702, :])\n",
        "\n",
        "  #print(\"preds_mid.shape is {}\".format(preds_mid.shape))\n",
        "\n",
        "  preds_mid_2 = preds_mid.reshape(-1, 2)\n",
        "\n",
        "  oa_preds = preds[0, 0:702, :] # oa stands for overall predictions\n",
        "\n",
        "  oa_preds = np.concatenate((oa_preds, preds_mid_2), axis = 0)\n",
        "\n",
        "  oa_preds = np.concatenate((oa_preds, preds[-1, 100:, :]), axis = 0)\n",
        "\n",
        "  return oa_preds\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gudTIR2iqQRY"
      },
      "source": [
        "def my_loss_fn(y_true, y_pred):\n",
        "  weight = tf.constant([1.0])\n",
        "  squared_difference = tf.square(y_true - y_pred)\n",
        "\n",
        "  # squared_difference[:, 1] =  squared_difference[:, 1] * y_true[:, 0]\n",
        "\n",
        "  # squared_difference[:, 3] =  squared_difference[:, 3] * y_true[:, 2]\n",
        "  ss0 = squared_difference[:, :, 0] * 0 + 1\n",
        "  ss1 = y_true[:, :, 0] \n",
        "  ss2 = y_true[:, :, 0]\n",
        "\n",
        "  ss3 = squared_difference[:, :, 3] * 0 + 1\n",
        "  ss4 = y_true[:, :, 3] \n",
        "  ss5 = y_true[:, :, 3]\n",
        "\n",
        "\n",
        "\n",
        "  sss = tf.stack((ss0, ss1, ss2, ss3, ss4, ss5), axis = 2)\n",
        "  \n",
        "  squared_difference =  tf.multiply(squared_difference, sss)\n",
        "\n",
        "\n",
        "  return tf.reduce_sum(squared_difference, axis=[-1, -2])  # Note the `axis=-1`"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdi8wxuBIXLf"
      },
      "source": [
        "def binary_acc(y_true, y_pred):\n",
        "  threshold = tf.constant([0.5])\n",
        "\n",
        "  binary_true = tf.stack((y_true[:, :, 0], y_true[:, :, 3]), axis=1)\n",
        "  binary_pred = tf.stack((y_pred[:, :, 0], y_pred[:, :, 3]), axis=1)\n",
        "\n",
        "  binary_true = tf.greater_equal(binary_true, threshold)\n",
        "  binary_pred = tf.greater_equal(binary_pred, threshold)\n",
        "\n",
        "  # binary_pred = tf.greater(y_pred[:, [0, 2]], threshold)\n",
        "\n",
        "  # acc = tf.square(y_true - y_pred)\n",
        "  acc = tf.cast((binary_true == binary_pred), tf.float32)\n",
        "\n",
        "  return tf.reduce_mean(acc, axis=[-1, -2])  # Note the `axis=-1`"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deO0w6SdyGAU"
      },
      "source": [
        "class TimeAcc(tf.keras.metrics.Metric):\n",
        "\n",
        "  def __init__(self, name='time_accuracy', **kwargs):\n",
        "    super(TimeAcc, self).__init__(name=name, **kwargs)\n",
        "    self.time_correct_1 = self.add_weight(name='time_correct_1', initializer='zeros')\n",
        "    self.time_count_1 = self.add_weight(name='time_count_1', initializer='zeros')\n",
        "    self.time_correct_3 = self.add_weight(name='time_correct_3', initializer='zeros')\n",
        "    self.time_count_3 = self.add_weight(name='time_count_3', initializer='zeros')\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    tolerance = tf.constant([0.25])\n",
        "    zero_lim = tf.constant([0.0])\n",
        "\n",
        "    y_true_0 = y_true[:, :, 0]\n",
        "    y_true_1 = y_true[:, :, 1]\n",
        "\n",
        "    y_pred_0 = y_pred[:, :, 0]\n",
        "    y_pred_1 = y_pred[:, :, 1]\n",
        "\n",
        "    time_diff_1 = tf.abs(y_pred_1 - y_true_1)\n",
        "\n",
        "    time_correct_1 = tf.cast(tf.less_equal(time_diff_1, tolerance), dtype = np.float32)\n",
        "\n",
        "    time_correct_1 = tf.multiply(time_correct_1, y_true_0)\n",
        "\n",
        "    self.time_count_1.assign_add(tf.reduce_sum(y_true_0, axis=None))\n",
        "\n",
        "    self.time_correct_1.assign_add(tf.reduce_sum(time_correct_1, axis = None))\n",
        "\n",
        "  def result(self):\n",
        "    time_acc_1 = self.time_correct_1 / self.time_count_1\n",
        "    return time_acc_1\n",
        "\n",
        "  def reset_states(self):\n",
        "    self.time_correct_1.assign(0)\n",
        "    self.time_count_1.assign(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fncNqYl7wVx"
      },
      "source": [
        "initial_learning_rate = 0.001\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=2500,\n",
        "    decay_rate=0.84,\n",
        "    staircase=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ta-ND5ezwD_"
      },
      "source": [
        "# This optimises val loss for Wave-U-Net YOHO\n",
        "# Back to Val Binary acc.\n",
        "\n",
        "import os\n",
        "class MyCustomCallback_3(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, model_dir, patience=0):\n",
        "    super(MyCustomCallback_3, self).__init__()\n",
        "    self.patience = patience\n",
        "    # best_weights to store the weights at which the minimum loss occurs.\n",
        "    self.best_weights = None\n",
        "    self.model_best_path = os.path.join(model_dir, 'model-best.h5')\n",
        "    self.model_last_path = os.path.join(model_dir, 'model-last-epoch.h5')\n",
        "    self.custom_params = {\"best_loss\":np.inf, \"last_epoch\":0}\n",
        "    \n",
        "    self.custom_params_path = os.path.join(model_dir, 'custom_params.pickle')\n",
        "    if os.path.isfile(self.custom_params_path):\n",
        "      with open(self.custom_params_path, 'rb') as f:\n",
        "        self.custom_params = pickle.load(f)\n",
        "      # best_model = tf.keras.models.load_model(self.model_best_path, custom_objects={'my_loss_fn':my_loss_fn, \n",
        "      #             'binary_acc':binary_acc, 'TCN':TCN(), 'SpeechF1':SpeechF1(), 'MusicF1':MusicF1(),\n",
        "      #             'OnAcc':OnAcc(), 'OnOffAcc':OnOffAcc(),'AudioClipLayer':AudioClipLayer(), \n",
        "      #             'InterpolationLayer':InterpolationLayer(), 'CropLayer':CropLayer(),\n",
        "      #             'IndependentOutputLayer':IndependentOutputLayer(), 'DiffOutputLayer':DiffOutputLayer()})\n",
        "      # best_model = tf.keras.models.clone_model(self.model)\n",
        "      # best_model.load_weights(self.model_best_path)\n",
        "      # self.best_weights = best_model.get_weights()\n",
        "\n",
        "\n",
        "  def on_train_begin(self, logs=None):\n",
        "    # The number of epoch it has waited when loss is no longer minimum.\n",
        "    self.wait = 0\n",
        "    # The epoch the training stops at.\n",
        "    self.stopped_epoch = 0\n",
        "    # Initialize the best F1 as 0.0.\n",
        "    self.is_impatient = False\n",
        "\n",
        "  def on_train_end(self, logs=None):\n",
        "    if not self.is_impatient:\n",
        "      print(\"Restoring model weights from the end of the best epoch.\")\n",
        "      self.model.set_weights(self.best_weights)\n",
        "      # temp_model_path = self.model_path.replace(\".h5\", \"_temp.h5\")\n",
        "      #os.remove(temp_model_path)\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    current_val_loss = logs.get(\"val_loss\")\n",
        "    self.model.save_weights(self.model_last_path)\n",
        "    self.custom_params[\"last_epoch\"] = self.custom_params[\"last_epoch\"] + 1\n",
        "\n",
        "    if current_val_loss < self.custom_params['best_loss']:\n",
        "      self.custom_params['best_loss'] = current_val_loss\n",
        "      self.wait = 0\n",
        "      self.best_weights = self.model.get_weights()\n",
        "      self.model.save_weights(self.model_best_path)\n",
        "\n",
        "    else:\n",
        "        self.wait += 1\n",
        "        if self.wait >= self.patience:\n",
        "            self.stopped_epoch = epoch\n",
        "            self.is_impatient = True\n",
        "            self.model.stop_training = True\n",
        "            print(\"Restoring model weights from the end of the best epoch.\")\n",
        "            self.model.set_weights(self.best_weights)\n",
        "            #os.remove(temp_model_path)\n",
        "    with open(self.custom_params_path, 'wb') as f:\n",
        "      pickle.dump(self.custom_params, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x_jjL8-zen_"
      },
      "source": [
        "# The YOHO network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LTnhXH5cosg"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhfZwpOncwPb"
      },
      "source": [
        "LAYER_DEFS = [\n",
        "    # (layer_function, kernel, stride, num_filters)\n",
        "    ([3, 3], 1,   64),\n",
        "    ([3, 3], 2,  128),\n",
        "    ([3, 3], 1,  128),\n",
        "    ([3, 3], 2,  256),\n",
        "    ([3, 3], 1,  256),\n",
        "    ([3, 3], 2,  512),\n",
        "    ([3, 3], 1,  512),\n",
        "    ([3, 3], 1,  512),\n",
        "    ([3, 3], 1,  512),\n",
        "    ([3, 3], 1,  512),\n",
        "    ([3, 3], 1,  512),\n",
        "    ([3, 3], 2, 1024),\n",
        "    ([3, 3], 1, 1024),\n",
        "    ([3, 3], 1, 512),\n",
        "    ([3, 3], 1, 256),\n",
        "    ([3, 3], 1, 128),\n",
        "    # ([3, 3], 1, 128),\n",
        "    # ([3, 3], 1, 128)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PMpLqA-cfsq"
      },
      "source": [
        "\"\"\"\n",
        "Manually define YOHO\n",
        "\"\"\"\n",
        "\n",
        "# params = yamnet_params.Params()\n",
        "m_features = tf.keras.Input(shape=(801, 64, 1), name=\"mel_input\")\n",
        "X = m_features\n",
        "# X = tf.keras.layers.Reshape((801, 64, 1))(X)\n",
        "X = tf.keras.layers.Conv2D(filters = 32, kernel_size=[3, 3], strides=2, padding='same', use_bias=False, activation=None, name = \"layer1/conv\")(X)\n",
        "X = tf.keras.layers.BatchNormalization(center=True, scale=False, epsilon=1e-4, name = \"layer1/bn\")(X)\n",
        "X = tf.keras.layers.ReLU(name=\"layer1/relu\")(X)\n",
        "\n",
        "for i in range(len(LAYER_DEFS)):\n",
        "  X = tf.keras.layers.DepthwiseConv2D(kernel_size=LAYER_DEFS[i][0], strides = LAYER_DEFS[i][1], depth_multiplier=1, padding='same', use_bias=False,\n",
        "                                      activation=None, name=\"layer\"+ str(i + 2)+\"/depthwise_conv\")(X)\n",
        "  X = tf.keras.layers.BatchNormalization(center=True, scale=False, epsilon=1e-4, name = \"layer\"+ str(i + 2)+\"/depthwise_conv/bn\")(X)\n",
        "  X = tf.keras.layers.ReLU(name=\"layer\"+ str(i + 2)+\"/depthwise_conv/relu\")(X)\n",
        "  X = tf.keras.layers.Conv2D(filters = LAYER_DEFS[i][2], kernel_size=[1, 1], strides=1, padding='same', use_bias=False, activation=None,\n",
        "                             name = \"layer\"+ str(i + 2)+\"/pointwise_conv\")(X)\n",
        "  X = tf.keras.layers.BatchNormalization(center=True, scale=False, epsilon=1e-4, name = \"layer\"+ str(i + 2)+\"/pointwise_conv/bn\")(X)\n",
        "  X = tf.keras.layers.ReLU(name=\"layer\"+ str(i + 2)+\"/pointwise_conv/relu\")(X)\n",
        "\n",
        "\n",
        "_, _, sx, sy = X.shape\n",
        "X = tf.keras.layers.Reshape((-1, int(sx * sy)))(X)\n",
        "\n",
        "pred = tf.keras.layers.Conv1D(6,kernel_size=1, activation=\"sigmoid\")(X)\n",
        "model = tf.keras.Model(\n",
        "      name='yamnet_frames', inputs=m_features,\n",
        "      outputs=[pred])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxlTJn22ct3K"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8Lo2dj4-gUE"
      },
      "source": [
        "\"\"\"\n",
        "BInary accuracy is not a valid measure for the YOHO algorithm. However, it gives a rough idea of how the model is doing because all the values are normalized between 0 and 1.\n",
        "The metrics are implemented in the testing section and val loss is used for early stopping.\n",
        "\"\"\"\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss=my_loss_fn, metrics=[binary_acc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaYq2kmW2pDY"
      },
      "source": [
        "# \"\"\"\n",
        "# The CRNN model used for ICASSP\n",
        "# \"\"\"\n",
        "\n",
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras import layers\n",
        "\n",
        "# mel_input = keras.Input(shape=(801, 64, 1), name=\"mel_input\")\n",
        "# X = mel_input\n",
        "\n",
        "# # X = tf.keras.layers.Reshape((801, 64, 1))(X)\n",
        "# # print(X.shape)\n",
        "\n",
        "# X = tf.keras.layers.Conv2D(filters=16, kernel_size=7, strides=1, padding='same')(X)\n",
        "# X = layers.BatchNormalization(momentum=0.0)(X)\n",
        "# X = tf.keras.layers.Activation('relu')(X)\n",
        "# X = tf.keras.layers.MaxPool2D(pool_size=(1, 2))(X)\n",
        "# X = tf.keras.layers.Dropout(rate = 0.2)(X)\n",
        "\n",
        "# X = tf.keras.layers.Conv2D(filters=64, kernel_size=7, strides=1, padding='same')(X)\n",
        "# X = layers.BatchNormalization(momentum=0.0)(X)\n",
        "# X = tf.keras.layers.Activation('relu')(X)\n",
        "# X = tf.keras.layers.MaxPool2D(pool_size=(1, 2))(X)\n",
        "# X = layers.Dropout(rate = 0.2)(X)\n",
        "\n",
        "# print(X.shape)\n",
        "# _, _, sx, sy = X.shape\n",
        "# X = tf.keras.layers.Reshape((-1, int(sx * sy)))(X)\n",
        "\n",
        "# X = layers.Bidirectional(layers.GRU(80, return_sequences = True))(X)\n",
        "# X = layers.BatchNormalization(momentum=0.0)(X)\n",
        "\n",
        "# X = layers.Bidirectional(layers.GRU(80, return_sequences = True))(X)\n",
        "# X = layers.BatchNormalization(momentum=0.0)(X)\n",
        "\n",
        "# pred = layers.TimeDistributed(layers.Dense(2, activation='sigmoid'))(X)\n",
        "\n",
        "# model = keras.Model(inputs = [mel_input], outputs = [pred])\n",
        "\n",
        "# keras.utils.plot_model(model, \"CRNN.png\", show_shapes=True)\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "#     loss=[keras.losses.BinaryCrossentropy()], metrics=['binary_accuracy'] #, 'categorical_accuracy', tf.keras.metrics.Precision(class_id=0), tf.keras.metrics.Precision(class_id=1), tf.keras.metrics.Recall(class_id=0), tf.keras.metrics.Recall(class_id=1)]\n",
        "# )\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zbsaUChgkhc"
      },
      "source": [
        "# model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=my_loss_fn, metrics=[binary_acc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdF9VFqOI8Xv"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "root_dir = \"/content/Models\"\n",
        "model_name = 'YOHO-1'\n",
        "model_dir = os.path.join(root_dir, model_name)\n",
        "\n",
        "try: \n",
        "    os.mkdir(model_dir) \n",
        "except OSError as error: \n",
        "    pass  \n",
        "\n",
        "%load_ext tensorboard\n",
        "import datetime, os\n",
        "logdir = os.path.join(root_dir)\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(os.path.join(root_dir, model_name), histogram_freq=1)\n",
        "\n",
        "%tensorboard --logdir \"{logdir}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4fL8Qbf2WpF"
      },
      "source": [
        "initial_epoch = 0\n",
        "p = os.path.join(model_dir, 'custom_params.pickle')\n",
        "if os.path.isfile(p):\n",
        "  print(\"Existing model found. Loading weights and training ...\")\n",
        "  with open(p, 'rb') as f:\n",
        "    custom_params = pickle.load(f)\n",
        "    last_epoch = custom_params['last_epoch']\n",
        "    initial_epoch = last_epoch\n",
        "  model_path = os.path.join(model_dir, 'model-best.h5')\n",
        "  print(model_path)\n",
        "  model.load_weights(model_path)\n",
        "\n",
        "  # model.load_weights(model_path)\n",
        "  model.fit(training_generator, validation_data=validation_generator, epochs=300, initial_epoch=initial_epoch,\n",
        "            callbacks=[MyCustomCallback_3(model_dir, patience=15), tensorboard_callback], verbose=1)\n",
        "  \n",
        "else:\n",
        "  print(\"No existing model found. Begin training ...\")\n",
        "\n",
        "  model.fit(training_generator, validation_data=validation_generator, epochs=300,\n",
        "            callbacks=[MyCustomCallback_3(model_dir, patience=15), tensorboard_callback], verbose=1)\n",
        "  \n",
        "  # workers=1,\n",
        "  #   use_multiprocessing=False,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# If you encounter an error in the above code block, please check if the initial 'wget' blocks were executed properly and the data was downloaded."
      ],
      "metadata": {
        "id": "WWZW7zhDDLZZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaJYugIkIwOA"
      },
      "source": [
        "model.load_weights(\"/content/Models/YOHO-1/model-best.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tfab0XQzJIZ"
      },
      "source": [
        "model.evaluate(validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngtAYLYfJcyp"
      },
      "source": [
        "Please note that binary accuracy is not a valid measure for the YOHO algorithm. However, it gives a rough idea of how the model is doing because all the values are normalized between 0 and 1.\n",
        "The metrics for F1 are implemented in the testing section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fCf2_JF_1XH"
      },
      "source": [
        "\"\"\"\n",
        "An evaluation when training was complete\n",
        "\"\"\"\n",
        "model.evaluate(validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtszLlvSqmqE"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9d4BlKU5S-D"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3Z6eDKJuMZS"
      },
      "source": [
        "def smooth_output(output, min_speech=1.3, min_music=3.4, max_silence_speech=0.4, max_silence_music=0.6):\n",
        "    duration_frame = 220 / 22050\n",
        "    n_frame = output.shape[1]\n",
        "\n",
        "    start_music = -1000\n",
        "    start_speech = -1000\n",
        "\n",
        "    for i in range(n_frame):\n",
        "        if output[0, i] == 1:\n",
        "            if i - start_speech > 1:\n",
        "                if (i - start_speech) * duration_frame <= max_silence_speech:\n",
        "                    output[0, start_speech:i] = 1\n",
        "\n",
        "            start_speech = i\n",
        "\n",
        "        if output[1, i] == 1:\n",
        "            if i - start_music > 1:\n",
        "                if (i - start_music) * duration_frame <= max_silence_music:\n",
        "                    output[1, start_music:i] = 1\n",
        "\n",
        "            start_music = i\n",
        "\n",
        "    start_music = -1000\n",
        "    start_speech = -1000\n",
        "\n",
        "    for i in range(n_frame):\n",
        "        if i != n_frame - 1:\n",
        "            if output[0, i] == 0:\n",
        "                if i - start_speech > 1:\n",
        "                    if (i - start_speech) * duration_frame <= min_speech:\n",
        "                        output[0, start_speech:i] = 0\n",
        "\n",
        "                start_speech = i\n",
        "\n",
        "            if output[1, i] == 0:\n",
        "                if i - start_music > 1:\n",
        "                    if (i - start_music) * duration_frame <= min_music:\n",
        "                        output[1, start_music:i] = 0\n",
        "\n",
        "                start_music = i\n",
        "        else:\n",
        "            if i - start_speech > 1:\n",
        "                if (i - start_speech) * duration_frame <= min_speech:\n",
        "                    output[0, start_speech:i + 1] = 0\n",
        "\n",
        "            if i - start_music > 1:\n",
        "                if (i - start_music) * duration_frame <= min_music:\n",
        "                    output[1, start_music:i + 1] = 0\n",
        "\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ateHmQta8_l2"
      },
      "source": [
        "def smoothe_events(events):\n",
        "  music_events = []\n",
        "  speech_events = []\n",
        "  for e in events:\n",
        "    if e[2] == \"speech\":\n",
        "      speech_events.append(e)\n",
        "    elif e[2] == \"music\":\n",
        "      music_events.append(e)\n",
        "\n",
        "  speech_events.sort(key=lambda x: x[0])\n",
        "  music_events.sort(key=lambda x: x[0])\n",
        "\n",
        "\n",
        "  start_speech = -1000\n",
        "  stop_speech = -1000\n",
        "\n",
        "  speech_events_2 = []\n",
        "\n",
        "  max_speech_silence = 0.8\n",
        "  max_music_silence = 0.8\n",
        "  min_dur_speech = 0.8\n",
        "  min_dur_music = 3.4\n",
        "\n",
        "  count = 0\n",
        "\n",
        "  while count < len(speech_events) - 1:\n",
        "    if (speech_events[count][1] >= speech_events[count + 1][0]) or (speech_events[count + 1][0] - speech_events[count][1] <= max_speech_silence):\n",
        "      speech_events[count][1] = max(speech_events[count + 1][1], speech_events[count][1])\n",
        "      del speech_events[count + 1]\n",
        "    else:\n",
        "      count += 1\n",
        "\n",
        "  count = 0\n",
        "\n",
        "  while count < len(music_events) - 1:\n",
        "    if (music_events[count][1] >= music_events[count + 1][0]) or (music_events[count + 1][0] - music_events[count][1] <= max_music_silence):\n",
        "      music_events[count][1] = max(music_events[count + 1][1], music_events[count][1])\n",
        "      del music_events[count + 1]\n",
        "    else:\n",
        "      count += 1\n",
        "\n",
        "\n",
        "  smooth_events = music_events + speech_events\n",
        "\n",
        "\n",
        "  count = 0\n",
        "  while count < len(smooth_events):\n",
        "    if smooth_events[count][1] - smooth_events[count][0] < min_dur_speech and smooth_events[count][2] == \"speech\":\n",
        "      del smooth_events[count]\n",
        "\n",
        "    elif smooth_events[count][1] - smooth_events[count][0] < min_dur_music and smooth_events[count][2] == \"music\":\n",
        "      del smooth_events[count]\n",
        "\n",
        "    else:\n",
        "      count += 1\n",
        "\n",
        "  for i in range(len(smooth_events)):\n",
        "    smooth_events[i][0] = round(smooth_events[i][0], 3)\n",
        "    smooth_events[i][1] = round(smooth_events[i][1], 3)\n",
        "\n",
        "  smooth_events.sort(key=lambda x: x[0])\n",
        "\n",
        "  return smooth_events"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2XmtQuB5VFP"
      },
      "source": [
        "\"\"\"\n",
        "Make predictions for full audio --- vectorised implementation.\n",
        "\"\"\"\n",
        "def mk_preds_vector(audio_path, hop_size = 6.0, discard = 1.0, win_length = 8.0, sampling_rate = 22050):\n",
        "  in_signal, in_sr = sf.read(audio_path)\n",
        "\n",
        "  # Resample the audio file.\n",
        "  in_signal_22k = librosa.resample(in_signal, orig_sr=in_sr, target_sr=sampling_rate)\n",
        "  in_signal = np.copy(in_signal_22k)\n",
        "\n",
        "  audio_clip_length_samples = in_signal.shape[0]\n",
        "  print('audio_clip_length_samples is {}'.format(audio_clip_length_samples))\n",
        "\n",
        "  hop_size_samples = int(hop_size * sampling_rate)\n",
        "  # hop_size_samples = 220 * 602 - 1\n",
        "\n",
        "  win_length_samples = int(win_length * sampling_rate)\n",
        "  # win_length_samples = 220 * 802 - 1\n",
        "\n",
        "  n_preds = int(math.ceil((audio_clip_length_samples - win_length_samples) / hop_size_samples)) + 1\n",
        "\n",
        "  # n_preds = int()\n",
        "\n",
        "  #print('n_preds is {}'.format(n_preds))\n",
        "\n",
        "  in_signal_pad = np.zeros(((n_preds - 1) * hop_size_samples) + win_length_samples)\n",
        "  # in_signal_pad = np.zeros((n_preds * hop_size_samples + 200 * 220))\n",
        "\n",
        "  #print('in_signal_pad.shape is {}'.format(in_signal_pad.shape))\n",
        "\n",
        "  in_signal_pad[0:audio_clip_length_samples] = in_signal\n",
        "\n",
        "  preds = np.zeros((n_preds, 26, 2))\n",
        "  mss_in = np.zeros((n_preds, 801, 64))\n",
        "  events = []\n",
        "\n",
        "  for i in range(n_preds):\n",
        "    seg = in_signal_pad[i * hop_size_samples:(i * hop_size_samples) + win_length_samples]\n",
        "    #print('seg.shape is {}'.format(seg.shape))\n",
        "    seg = librosa.util.normalize(seg)\n",
        "    seg_t = librosa.resample(seg, orig_sr=22050, target_sr=16000)\n",
        "    seg = seg_t\n",
        "\n",
        "    mss = get_log_melspectrogram(seg)\n",
        "    M = mss.T\n",
        "    mss_in[i, :, :] = M\n",
        "\n",
        "  preds = model.predict(mss_in)\n",
        "  # preds[:, 0] = (p[:, 0] >= 0.5).astype(np.float)\n",
        "  # preds[:, 2] = (p[:, 2] >= 0.5).astype(np.float)\n",
        "\n",
        "  events = []\n",
        "\n",
        "  for j in range(n_preds):\n",
        "    p = preds[j, :, :]\n",
        "    events_curr = []\n",
        "    win_width = win_length / 26\n",
        "    for i in range(len(p)):\n",
        "      if p[i][0] >= 0.5:\n",
        "        start = win_width * i + win_width * p[i][1]\n",
        "        end = win_width * i + win_width * p[i][2]\n",
        "        events_curr.append([start, end, \"speech\"])\n",
        "\n",
        "      if p[i][3] >= 0.5:\n",
        "        start = win_width * i + win_width * p[i][4]\n",
        "        end = win_width * i + win_width * p[i][5]\n",
        "        events_curr.append([start, end, \"music\"])\n",
        "\n",
        "    se = events_curr\n",
        "    if j == 0:\n",
        "      start = 0.0\n",
        "      end = start + win_length\n",
        "      if preds.shape[0] > 1:\n",
        "        end -= discard\n",
        "\n",
        "      # print(\"start: {}   end: {}\".format(start, end))\n",
        "    elif j == n_preds - 1:\n",
        "      start = j * hop_size + discard\n",
        "      end = start - discard + win_length\n",
        "      # print(\"start: {}   end: {}\".format(start, end))\n",
        "\n",
        "    else:\n",
        "      start = j * hop_size + discard\n",
        "      end = start + win_length - discard\n",
        "      # print(\"start: {}   end: {}\".format(start, end))\n",
        "    \n",
        "    for k in range(len(se)):\n",
        "      se[k][0] = max(start, se[k][0] + j * hop_size)\n",
        "      se[k][1] = min(end, se[k][1] + j * hop_size)\n",
        "\n",
        "    # print(se)\n",
        "\n",
        "\n",
        "    for see in se:\n",
        "     events.append(see) \n",
        "    \n",
        "  # print(events)\n",
        "  smooth_events = smoothe_events(events)\n",
        "\n",
        "  return smooth_events"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xwVo9uHv_nr"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuUdlsIqFdk3"
      },
      "source": [
        "start_time = time.time()\n",
        "see = mk_preds_vector(\"/content/test_6.wav\")\n",
        "print(see)\n",
        "stop_time = time.time()\n",
        "print(\"Duration: {}\".format(stop_time - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vIX8ytBBoXo"
      },
      "source": [
        "tt = \"/content/test_6.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB8H3gQPBl4M"
      },
      "source": [
        "see = mk_preds_vector(tt.replace(\".txt\",\".wav\"))\n",
        "n_label = tt.replace(\".txt\",\"-se-prediction.txt\")\n",
        "\n",
        "with open(n_label, 'w') as fp:\n",
        "  fp.write('\\n'.join('{},{},{}'.format(round(x[0], 5), round(x[1], 5), x[2]) for x in see))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o83Pewqc6bsA"
      },
      "source": [
        "# mk_preds_vector(\"/content/test audio/ROTDevonGoldenHour01022020090000.wav\")\n",
        "start_time = time.time()\n",
        "see = mk_preds_vector(\"/content/test audio/ROTDevonGoldenHour01022020090000.wav\")\n",
        "print(see)\n",
        "stop_time = time.time()\n",
        "print(\"Duration: {}\".format(stop_time - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkKP57sS8rrn"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SNzUw2I_O6I"
      },
      "source": [
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqENwx6p_iN7"
      },
      "source": [
        "def read_annotation(filename):\n",
        "    events = []\n",
        "    with open(filename, 'r') as csvfile:\n",
        "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
        "        for row in spamreader:\n",
        "            row[0] = float(row[0])\n",
        "            row[1] = float(row[1])\n",
        "            events.append(row)\n",
        "    return events"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dZ0X5sn_MHg"
      },
      "source": [
        "\"\"\"\n",
        "Copy audio files of test set into a separate folder called 'test audio'\n",
        "\"\"\"\n",
        "\n",
        "audio_files = ['/content/drive/My Drive/MuSpeak/a3-mel-train.npy', '/content/drive/My Drive/MuSpeak/a4-mel-train.npy', '/content/drive/My Drive/BBC RadioMe dataset/ROTDevonGoldenHour28012020090000-mel-train.npy', '/content/drive/My Drive/BBC RadioMe dataset - 2/ROTDevonMorning28012020100000_pt1-mel-train.npy', '/content/drive/My Drive/BBC RadioMe dataset/ROTDevonGoldenHour30012020090000-mel-train.npy', '/content/drive/My Drive/BBC RadioMe dataset/ROTDevonGoldenHour01022020090000-mel-train.npy']\n",
        "\n",
        "for i in range(len(audio_files)):\n",
        "  temp = audio_files[i].replace(\"-mel-train.npy\",\".txt\")\n",
        "  audio_files[i] = temp  \n",
        "\n",
        "destination = \"/content/test audio/\"\n",
        "try: \n",
        "    os.mkdir(destination) \n",
        "except OSError as error: \n",
        "    pass  \n",
        "\n",
        "\n",
        "for a in audio_files:\n",
        "  shutil.copy(a, destination)\n",
        "  shutil.copy(a.replace(\".txt\",\".wav\"), destination)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Smoothe the labels in the .txt files\n",
        "\"\"\"\n",
        "import csv\n",
        "\n",
        "destination = \"/content/test audio/\"\n",
        "audio_files = glob.glob(destination + \"*.txt\")\n",
        "\n",
        "for a in audio_files:\n",
        "  events = read_annotation(a)\n",
        "  smooth_events = smoothe_events(events)\n",
        "\n",
        "  temp_file = a.replace(\".txt\", \"-temp.txt\")\n",
        "  with open(temp_file, 'w', newline='') as csvfile:\n",
        "      spamwriter = csv.writer(csvfile, delimiter=',',\n",
        "                              quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "      for event in smooth_events:\n",
        "        spamwriter.writerow(event)\n",
        "  shutil.copyfile(temp_file, a)\n",
        "  os.remove(temp_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf9Fqc3u6WBk"
      },
      "source": [
        "model.load_weights(\"/content/drive/My Drive/Post-ICASSP 2021/Reliving transitions/Models/CRNN-3/model-best.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKmsmE7I-GBU"
      },
      "source": [
        "\"\"\"\n",
        "Evaluation on Test set.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# models = glob.glob('/content/drive/My Drive/Experiments/ICASSP 2021/e1/Models/*.h5', recursive = False)\n",
        "\n",
        "# models = ['/content/drive/My Drive/ICASSP 2021/e1/Models/model 1_3.h5', '/content/drive/My Drive/ICASSP 2021/e1/Models/model 1_4.h5', '/content/drive/My Drive/ICASSP 2021/e1/Models/model 2_4.h5',  '/content/drive/My Drive/ICASSP 2021/e1/Models/model 2_5.h5', '/content/drive/My Drive/ICASSP 2021/e1/Models/model 4_1.h5', '/content/drive/My Drive/ICASSP 2021/e1/Models/model 4_2.h5', '/content/drive/My Drive/ICASSP 2021/e1/Models/model 4_3.h5',  '/content/drive/My Drive/ICASSP 2021/e1/Models/model 4_4.h5',   '/content/drive/My Drive/ICASSP 2021/e1/Models/model 4_5.h5']\n",
        "# models = ['/content/drive/My Drive/ICASSP 2021/e1/Models/model 102_1.h5']\n",
        "# models = ['/content/drive/My Drive/Experiments/Models/e2/model48.h5']\n",
        "# models = ['/content/drive/My Drive/Post-ICASSP 2021/Experiments/Models/model d6_23/model-best.h5']\n",
        "\n",
        "\n",
        "# models = ['/content/drive/MyDrive/Post-ICASSP 2021/Experiments/5k + 10k comparison/B-GRU - 1/model-best.h5',\n",
        "#           '/content/drive/MyDrive/Post-ICASSP 2021/Experiments/5k + 10k comparison/B-LSTM - 1/model-best.h5',\n",
        "#           '/content/drive/MyDrive/Post-ICASSP 2021/Experiments/5k + 10k comparison/CRNN - 1/model-best.h5',\n",
        "#           '/content/drive/MyDrive/Post-ICASSP 2021/Experiments/5k + 10k comparison/TCN - 1/model-best.h5',\n",
        "#           '/content/drive/MyDrive/Post-ICASSP 2021/Experiments/5k + 10k comparison/CNN - 1/model-best.h5']\n",
        "\n",
        "\n",
        "\n",
        "destination = \"/content/test audio/\"\n",
        "test_set = glob.glob(destination + \"*[0-9].txt\")\n",
        "\n",
        "print(test_set)\n",
        "\n",
        "eval_path = \"/content/drive/My Drive/Post-ICASSP 2021/Reliving transitions/evaluations/eval - test set/\"\n",
        "\n",
        "for tt in test_set:\n",
        "  # ss, _ = sf.read(tt.replace(\".txt\",\".wav\"))\n",
        "  # oop = mk_preds_fa(tt.replace(\".txt\",\".wav\"))\n",
        "\n",
        "  #print(oop.shape)\n",
        "  # p_smooth = smooth_output(oop.T, min_speech = 0.8, min_music = 3.4, max_silence_speech = 0.8, max_silence_music = 0.8)\n",
        "  # p_smooth = p_smooth.T\n",
        "  see = mk_preds_vector(tt.replace(\".txt\",\".wav\"))\n",
        "  #print(see)\n",
        "  n_label = tt.replace(\".txt\",\"-se-prediction.txt\")\n",
        "\n",
        "  with open(n_label, 'w') as fp:\n",
        "    fp.write('\\n'.join('{},{},{}'.format(round(x[0], 5), round(x[1], 5), x[2]) for x in see))\n",
        "\n",
        "\"\"\"\n",
        "Code for second round of using sed_eval starts here.. This simply tests on one of the muspeak datasets\n",
        "\"\"\"\n",
        "\n",
        "se_dir = '/content/drive/My Drive/Data Synthesis/SE Audio Examples'\n",
        "n = 512\n",
        "\n",
        "file_list = [\n",
        "    {\n",
        "    'reference_file': tt,\n",
        "    'estimated_file': tt.replace(\".txt\",\"-se-prediction.txt\")\n",
        "    }\n",
        "    for tt in test_set\n",
        "]\n",
        "\n",
        "data = []\n",
        "\n",
        "# Get used event labels\n",
        "all_data = dcase_util.containers.MetaDataContainer()\n",
        "for file_pair in file_list:\n",
        "    reference_event_list = sed_eval.io.load_event_list(\n",
        "        filename=file_pair['reference_file']\n",
        "    )\n",
        "    estimated_event_list = sed_eval.io.load_event_list(\n",
        "        filename=file_pair['estimated_file']\n",
        "    )\n",
        "\n",
        "    data.append({'reference_event_list': reference_event_list,\n",
        "                'estimated_event_list': estimated_event_list})\n",
        "\n",
        "    all_data += reference_event_list\n",
        "\n",
        "event_labels = all_data.unique_event_labels\n",
        "\n",
        "# Start evaluating\n",
        "\n",
        "# Create metrics classes, define parameters\n",
        "segment_based_metrics = sed_eval.sound_event.SegmentBasedMetrics(\n",
        "    event_label_list=event_labels,\n",
        "    time_resolution=0.010\n",
        ")\n",
        "\n",
        "event_based_metrics = sed_eval.sound_event.EventBasedMetrics(\n",
        "    event_label_list=event_labels,\n",
        "    t_collar=0.500\n",
        ")\n",
        "\n",
        "# Go through files\n",
        "for file_pair in data:\n",
        "    segment_based_metrics.evaluate(\n",
        "        reference_event_list=file_pair['reference_event_list'],\n",
        "        estimated_event_list=file_pair['estimated_event_list']\n",
        "    )\n",
        "\n",
        "    event_based_metrics.evaluate(\n",
        "        reference_event_list=file_pair['reference_event_list'],\n",
        "        estimated_event_list=file_pair['estimated_event_list']\n",
        "    )\n",
        "\n",
        "# Get only certain metrics\n",
        "overall_segment_based_metrics = segment_based_metrics.results_overall_metrics()\n",
        "print(\"Accuracy:\", overall_segment_based_metrics['accuracy']['accuracy'])\n",
        "\n",
        "# Or print all metrics as reports\n",
        "\n",
        "model_basename = \"YamNet-23.h5\"\n",
        "seg_eval_basename = \"seg eval \" + model_basename.replace(\".h5\", \"\") + \".txt\"\n",
        "ev_eval_basename = \"event eval \" + model_basename.replace(\".h5\", \"\") + \".txt\"\n",
        "with open(os.path.join(eval_path, seg_eval_basename), mode='w') as fp:\n",
        "  fp.write(str(segment_based_metrics))\n",
        "\n",
        "with open(eval_path + \"/seg eval \" + model_basename.replace(\".h5\", \"\") + \".pickle\", 'wb') as f:\n",
        "  pickle.dump(segment_based_metrics, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open(os.path.join(eval_path, ev_eval_basename), mode = 'w') as fp:\n",
        "  fp.write(str(event_based_metrics))\n",
        "\n",
        "with open(eval_path + \"/event eval \" + model_basename.replace(\".h5\", \"\") + \".pickle\", 'wb') as f:\n",
        "  pickle.dump(event_based_metrics, f, pickle.HIGHEST_PROTOCOL)   "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
